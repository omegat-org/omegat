# Machine Translation SPI with multi-level context for LLM Support

## Status
**Proposed**

## Date
2025-12-27

## Context
OmegaT's existing Machine Translation (MT) Service Provider Interface (SPI) is designed for simple, segment-by-segment translation without persistent context. However, modern Large Language Models (LLMs) significantly benefit from "multi-level prompting," where translations are informed by project-wide instructions (e.g., style guides, domain knowledge) in addition to the source segment itself.

To support LLM-powered MT and quality checking (reasoning) via external plugins, the OmegaT core SPI needs to be enhanced to handle project-level context. This allows OmegaT to remain decoupled from specific LLM implementations and rapidly evolving LLM APIs while enabling high-quality, context-aware translations.

## Decision
We will extend the OmegaT core SPI to support multi-level context. This includes:
1.  Defining a mechanism to provide project-level context to MT and Issue providers.
2.  Updating the `IMachineTranslation` and `IIssueProvider` interfaces to accept this context.
3.  Ensuring the implementation of specific LLM logic remains in optional, external plugins.

## Proposed Changes

### 1. New Interface: `IContextSupplier`
A new interface `org.omegat.gui.exttrans.IContextSupplier` will be introduced. This interface allows providers to query for project-level context information.

### 2. Enhanced `IMachineTranslation` SPI
The `org.omegat.gui.exttrans.IMachineTranslation` interface will be updated with:
- `setContextSupplier(IContextSupplier supplier)`: Allows OmegaT core to pass a context supplier to the MT engine.
- Methods to handle more granular "suggestions" and metadata, enabling features like reasoning and alignment explanations.

### 3. Enhanced `IIssueProvider` SPI
The `org.omegat.gui.issues.IIssueProvider` interface will be updated to support context-aware issue detection. This enables LLM-based plugins to perform quality checks that consider project-level instructions and provide detailed reasoning for identified issues.

### 4. Leverage Existing `IMTGlossarySupplier`
We will continue to leverage `IMTGlossarySupplier` to provide terminology context, which can be combined with project-level context in LLM prompts for better accuracy.

## Consequences

### Positive
✅ **Clean Core**: OmegaT core remains agnostic of LLM-specific logic, APIs, and dependencies.
✅ **Extensibility**: Third-party developers can create specialized LLM plugins (local or remote) using a standardized SPI.
✅ **Independent Release Cycle**: Plugins can be updated frequently to match evolving LLM capabilities without requiring core OmegaT releases.
✅ **Contextual Quality**: Enables higher-quality translations and reasoning-based issue detection by providing the necessary context to plugins.

### Negative
- **SPI Complexity**: Increases the complexity of the MT and Issue Provider interfaces.
- **Coordination**: Requires careful design to ensure that different plugins (e.g., an MT plugin and an Issue Provider plugin) can share configuration and context effectively if they are part of the same suite.


----

## Optional Note: Reference Implementation (External LLM Plugin)
*(This section describes a potential design for an external plugin leveraging the new SPI; it is not part of the core OmegaT proposal.)*

OmegaT users have expressed interest in using Large Language Models (LLMs) for machine translation, specifically local LLMs to ensure data privacy and avoid recurring costs.
Frameworks like Ollama, LM Studio, llama.cpp, and GPT4All provide OpenAI-compatible APIs that can be leveraged on a user's local machine.

The proposed SPI changes enable an external LLM plugin with the following architecture:

### 1. MT Connectors and OpenAI Compatibility
The plugin can provide a generic connector for OpenAI-compatible APIs (Ollama, LM Studio, OpenAI, etc.) and dedicated connectors for other services (Azure, Google, Anthropic, etc.).

### 2. Project-Level Configuration (`omegat/llm.xml`)
The plugin can store its own project-specific settings (model selection, project prompt) in a separate file to ensure backward compatibility and keep the main project file clean.

### 3. Prompt Construction
The plugin constructs prompts by merging:
- **System Prompt**: Base instructions for the MT task.
- **Project Prompt**: Domain and style instructions from `IContextSupplier`.
- **Glossary Context**: Terminology from `IMTGlossarySupplier`.
- **Segment Prompt**: The actual source segment to translate.

### 4. Technical Architecture
```
┌──────────────────────────────────────┐          ┌──────────────────────────────────────┐
│             OmegaT Core              │          │      Optional LLM Plugin (JAR)       │
│                                      │          │                                      │
│  ┌────────────────────────────────┐  │          │  ┌────────────────────────────────┐  │
│  │ MT & Issue Management          │  │          │  │ UI: LLM Configuration          │  │
│  └─────────────┬──────────────────┘  │          │  └─────────────┬──────────────────┘  │
│                │                     │          │                │                     │
│                │ (1) Calls           │          │                ↓                     │
│                ▼                     │          │  ┌────────────────────────────────┐  │
│  ┌────────────────────────────────┐  │          │  │ LLMProperties                │──┼──→ (Storage: omegat/llm.xml)
│  │         Core SPI Layer         │  │          │  └─────────────┬──────────────────┘  │
│  │                                │  │          │                │                     │
│  │ IMachineTranslation  ──────────┼──┼──────────┼───▶ MTConnector (MT SPI)             │
│  │ IIssueProvider       ──────────┼──┼──────────┼───▶ Issue Provider (Issue SPI)       │
│  │                                │  │          │                │                     │
│  │ IContextSupplier     ◀─────────┼──┼──────────┼──── Prompt Construction              │
│  │ IMTGlossarySupplier  ◀─────────┼──┼──────────┼──── (Context-Aware)                  │
│  │                                │  │          │                │                     │
│  └─────────────┬──────────────────┘  │          │  ┌─────────────▼──────────────────┐  │
│                │                     │          │  │ Shared Plugin Infrastructure   │  │
│                │ (2) Provides        │          │  │ (API & Protocol Handling)      │  │
│                ▼                     │          │  └─────────────┬──────────────────┘  │
│  ┌────────────────────────────────┐  │          └────────────────┼─────────────────────┘
│  │ Project Context & Glossary     │  │                           │
│  └────────────────────────────────┘  │                           ↓
└──────────────────────────────────────┘          ┌──────────────────────────────────────┐
                                                  │ LLM API (Ollama, OpenAI, etc)        │
                                                  └──────────────────────────────────────┘
```
